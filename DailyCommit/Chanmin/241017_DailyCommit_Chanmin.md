
1. 하둡(Hadoop)의 역할: 데이터 저장 및 배치 처리
하둡은 주로 대규모 데이터를 저장하고, 그 데이터를 분산 환경에서 배치 처리하는 데 사용됩니다.
HDFS (Hadoop Distributed File System): 하둡의 파일 시스템으로, 대량의 데이터를 여러 대의 서버(노드)에 분산하여 저장합니다. 데이터의 크기가 매우 커질 경우, HDFS는 데이터를 복제하고 분산 저장해 안전성과 확장성을 제공합니다.
MapReduce: 하둡은 데이터를 배치로 처리하기 위해 MapReduce라는 분산 프로세싱 모델을 사용합니다. 이 방식은 데이터를 여러 서버에서 동시에 처리하고, 그 결과를 집계합니다. 하지만 속도가 느리다는 단점이 있습니다.


2. 스파크(Spark)의 역할: 데이터 처리 및 분석
스파크는 주로 데이터 분석이나 실시간 처리를 위해 사용됩니다. 하둡과 달리 스파크는 데이터를 메모리에서 처리하여 더 빠르게 데이터를 분석할 수 있습니다.
인메모리(In-memory) 처리: 스파크는 데이터를 메모리에 올려서 처리하므로 대규모 데이터를 빠르게 분석할 수 있습니다. 하둡의 MapReduce보다 속도가 훨씬 빠르며, 이를 통해 복잡한 데이터 처리와 분석 작업을 효율적으로 수행할 수 있습니다.
다양한 분석 기능: 스파크는 단순한 배치 처리 외에도 실시간 스트리밍 처리, 머신러닝 분석(Spark MLlib), 그래프 처리(GraphX) 등 다양한 기능을 제공합니다.
